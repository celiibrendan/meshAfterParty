{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: To process and save the inhibitory and excitatory neurons\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: To process and save the inhibitory and excitatory neurons\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sys\n",
    "sys.path.append(\"/meshAfterParty/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n",
      "WARNING:root:Need to pip install annotationframeworkclient to use dataset_name parameters\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.getcwd()\n",
    "\n",
    "import neuron_utils as nru\n",
    "nru = reload(nru)\n",
    "import neuron\n",
    "neuron=reload(neuron)\n",
    "import neuron_visualizations as nviz\n",
    "import time\n",
    "import system_utils as su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all of the meshes to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_type = \"meshafterparty\"\n",
    "cell_type = \"excitatory\"\n",
    "\n",
    "curr_dir = Path(\"../../inhibitory_excitatory\")\n",
    "neuron_files = list(curr_dir.iterdir())\n",
    "current_cells = [k for k in neuron_files if f\"_{cell_type}_\" in str(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0 size = 66.50314900000001\n",
      "File 1 size = 90.083909\n",
      "File 2 size = 16.53719\n",
      "File 3 size = 15.094439\n",
      "File 4 size = 15.498361000000001\n",
      "File 5 size = 14.430209999999999\n",
      "File 6 size = 36.159681\n"
     ]
    }
   ],
   "source": [
    "import system_utils as su\n",
    "for j,curr_file in enumerate(current_cells):\n",
    "    print(f\"File {j} size = {su.get_file_size(curr_file)/1000/1000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Excitatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Working on: ../../inhibitory_excitatory/100917645171610430_excitatory_8.off ---- \n",
      "\n",
      "\n",
      "\n",
      "----- Working on: ../../inhibitory_excitatory/89309550087617165_excitatory_5.off ---- \n",
      "\n",
      "--- 0) Having to preprocess the Neuron becuase no preprocessed data\n",
      "Please wait this could take a while.....\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "****** Phase A ***************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Arguments Using (adjusted for decimation):\n",
      " large_mesh_threshold= 15000.0 \n",
      "large_mesh_threshold_inner = 10000.0 \n",
      "soma_size_threshold = 1250.0 \n",
      "soma_size_threshold_max = 12000.0\n",
      "outer_decimation_ratio = 0.25\n",
      "inner_decimation_ratio = 0.25\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "Using port = 645\n",
      "xvfb-run -n 645 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165.off -o /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated.off -s /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/decimation_meshlab_25532137.mls\n",
      "Total found significant pieces before Poisson = [<trimesh.Trimesh(vertices.shape=(222888, 3), faces.shape=(449220, 3))>]\n",
      "----- working on large mesh #0: <trimesh.Trimesh(vertices.shape=(222888, 3), faces.shape=(449220, 3))>\n",
      "pre_largest_mesh_path = /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated_largest_piece.off\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "Using port = 5435\n",
      "xvfb-run -n 5435 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated_largest_piece.off -o /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated_largest_piece_poisson.off -s /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/poisson_841715.mls\n",
      "Total found significant pieces AFTER Poisson = [<trimesh.Trimesh(vertices.shape=(106726, 3), faces.shape=(213460, 3))>, <trimesh.Trimesh(vertices.shape=(48503, 3), faces.shape=(97002, 3))>, <trimesh.Trimesh(vertices.shape=(45843, 3), faces.shape=(91682, 3))>, <trimesh.Trimesh(vertices.shape=(8323, 3), faces.shape=(16642, 3))>]\n",
      "----- working on mesh after poisson #0: <trimesh.Trimesh(vertices.shape=(106726, 3), faces.shape=(213460, 3))>\n",
      "IN INPUT FILE VALIDATION LOOP\n",
      "LEAVING LOOP, MESH VALIDATED\n",
      "Using port = 6044\n",
      "xvfb-run -n 6044 -s \"-screen 0 800x600x24\" meshlabserver $@  -i /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated_largest_piece_poisson_largest_inner.off -o /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/neuron_89309550087617165_decimated_largest_piece_poisson_largest_inner_decimated.off -s /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/89309550087617165/decimation_meshlab_25786237.mls\n",
      "done exporting decimated mesh: neuron_89309550087617165_decimated_largest_piece_poisson_largest_inner.off\n",
      "1) Starting: Mesh importing and Pymesh fix\n",
      "loading mesh from vertices and triangles array\n",
      "1) Finished: Mesh importing and Pymesh fix: 0.0003635883331298828\n",
      "2) Staring: Generating CGAL segmentation for neuron\n",
      "Done writing OFF file\n",
      "\n",
      "Starting CGAL segmentation\n",
      "Right before cgal segmentation, clusters = 3, smoothness = 0.2, path_and_filename = /examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/temp/8930955008761716500_fixed \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-39adcf103e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#branch_skeleton_data=branch_skeleton_data,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0msuppress_preprocessing_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             suppress_output=False)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total time for processing: {time.time() - meshparty_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/neuron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mesh, segment_id, description, preprocessed_data, decomposition_type, mesh_correspondence, distance_by_mesh_center, meshparty_segment_size, meshparty_n_surface_downsampling, meshparty_adaptive_correspondence_after_creation, suppress_preprocessing_print, computed_attribute_dict, somas, branch_skeleton_data, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold, ignore_warnings, suppress_output, calculate_spines, widths_to_calculate)\u001b[0m\n\u001b[1;32m   1515\u001b[0m                                                             \u001b[0mbranch_skeleton_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbranch_skeleton_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m                                                             \u001b[0mcombine_close_skeleton_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_close_skeleton_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m                                                             combine_close_skeleton_nodes_threshold=combine_close_skeleton_nodes_threshold)\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- 0) Total time for preprocessing: {time.time() - neuron_start_time}\\n\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/preprocess_neuron.py\u001b[0m in \u001b[0;36mpreprocess_neuron\u001b[0;34m(mesh, mesh_file, segment_id, description, sig_th_initial_split, limb_threshold, filter_end_node_length, return_no_somas, decomposition_type, mesh_correspondence, distance_by_mesh_center, meshparty_segment_size, meshparty_n_surface_downsampling, somas, branch_skeleton_data, combine_close_skeleton_nodes, combine_close_skeleton_nodes_threshold)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         soma_mesh_list,run_time,total_soma_list_sdf = sm.extract_soma_center(segment_id,\n\u001b[1;32m   1142\u001b[0m                                                  \u001b[0mcurrent_neuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                                                  current_neuron.faces)\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0msoma_mesh_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_soma_list_sdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/soma_extraction_utils.py\u001b[0m in \u001b[0;36mextract_soma_center\u001b[0;34m(segment_id, current_mesh_verts, current_mesh_faces, outer_decimation_ratio, large_mesh_threshold, large_mesh_threshold_inner, soma_width_threshold, soma_size_threshold, inner_decimation_ratio, volume_mulitplier, side_length_ratio_threshold, soma_size_threshold_max, delete_files, backtrack_soma_mesh_to_original, boundary_vertices_threshold, poisson_backtrack_distance_threshold, close_holes)\u001b[0m\n\u001b[1;32m    279\u001b[0m                                      \u001b[0msmoothness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                                     \u001b[0msoma_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                                     \u001b[0mreturn_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                                     )\n\u001b[1;32m    283\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"soma_sdf_value = {soma_value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/whole_neuron_classifier_datajoint_adapted.py\u001b[0m in \u001b[0;36mextract_branches_whole_neuron\u001b[0;34m(import_Off_Flag, **kwargs)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2) Staring: Generating CGAL segmentation for neuron\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_cgal_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimport_CGAL_Flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimport_CGAL_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m     \u001b[0;31m#retrieves the cgal data from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/meshAfterParty/whole_neuron_classifier_datajoint_adapted.py\u001b[0m in \u001b[0;36mload_cgal_segmentation\u001b[0;34m(self, clusters, smoothness, import_CGAL_Flag, import_CGAL_paths)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcgal_Flag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Right before cgal segmentation, clusters = {clusters}, smoothness = {smoothness}, path_and_filename = {path_and_filename} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcgal_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_and_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finished CGAL segmentation algorithm: {time.time() - start_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Pseudocode:\n",
    "1) Load in the mesh\n",
    "2) extract out segment_id and description\n",
    "3) process the neuron using MP and save output\n",
    "4) Process neuron using MAP and save output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import time\n",
    "import neuron\n",
    "neuron = reload(neuron)\n",
    "\n",
    "\n",
    "\n",
    "for j,inh_mesh_file in enumerate(current_cells):\n",
    "    print(f\"\\n\\n----- Working on: {inh_mesh_file} ---- \\n\")\n",
    "    if j <1:\n",
    "        continue\n",
    "    #1) Load in the mesh\n",
    "    import trimesh_utils as tu\n",
    "    current_neuron_mesh = tu.load_mesh_no_processing(str(inh_mesh_file.absolute()))\n",
    "    \n",
    "    #2) extract out segment_id and description\n",
    "    file_parts = str(inh_mesh_file.name)[:-4].split(\"_\")\n",
    "\n",
    "    segment_id=int(file_parts[0])\n",
    "    description = \"_\".join(file_parts[1:])\n",
    "    \n",
    "    #3) process the neuron using MP and save output\n",
    "    \n",
    "    meshparty_time = time.time()\n",
    "    \n",
    "    current_neuron_inh = neuron.Neuron(\n",
    "            mesh=current_neuron_mesh,\n",
    "            segment_id=segment_id,\n",
    "            description=description,\n",
    "            decomposition_type=process_type,\n",
    "            #somas = somas_inh,\n",
    "            #branch_skeleton_data=branch_skeleton_data,\n",
    "            suppress_preprocessing_print=False,\n",
    "            suppress_output=False)\n",
    "    \n",
    "    print(f\"Total time for processing: {time.time() - meshparty_time}\")\n",
    "\n",
    "    # -- save output --\n",
    "    output_folder = curr_dir / Path(f\"{cell_type}_{process_type}\")\n",
    "    output_folder.mkdir(parents=True,exist_ok=True)\n",
    "    \n",
    "    current_neuron_inh.save_compressed_neuron(\n",
    "        output_folder = output_folder,\n",
    "        file_name=f\"{current_neuron_inh.segment_id}_{current_neuron_inh.description}_{process_type}\",\n",
    "        suppress_output=False\n",
    "        \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 3\n",
    "smoothness = 0.2\n",
    "path_and_filename = \"/examples/test_neurons/inhibitory_excitatory/excitatory_meshafterparty/temp/8930955008761716500_fixed\"\n",
    "csm.cgal_segmentation(path_and_filename,clusters,smoothness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved mesh to check that everything saved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuron_utils as nru\n",
    "nru = reload(nru)\n",
    "nviz = reload(nviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_neuron = nru.decompress_neuron(filepath=\"./inhibitory_excitatory/inhibitory_meshafterparty/90725377802114822_inhibitory_7_meshafterparty\",\n",
    "                     original_mesh=\"./inhibitory_excitatory/90725377802114822_inhibitory_7.off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
